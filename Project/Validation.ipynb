{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "#import logging\n",
    "\n",
    "#import string\n",
    "from nltk.tokenize import RegexpTokenizer # tokenizing\n",
    "from nltk.corpus import stopwords  # list of stop words\n",
    "from nltk.stem.wordnet import WordNetLemmatizer # lemmatizer\n",
    "\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import html\n",
    "\n",
    "from collections import defaultdict\n",
    "# Logging code taken from http://rare-technologies.com/word2vec-tutorial/\n",
    "#logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading model\n",
    "\n",
    "Choose one option from below.  The first 2 are the same model, which can be used to calculate a probability score for a phrase. The first is just the word vectors (no hidden layer weights). The second is the full model (can calculate score).\n",
    "\n",
    "The last file is the negative sampling model, which always for the 'predict_output_word' function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load full model with softmax, CBOW, and no negative sampling\n",
    "path = \"/Users/stevenfelix/Documents/DataScience_local/Insight/\"\n",
    "file = 'model_full_50M_sg0_sz250_win5_min3_hs1_neg0'\n",
    "model= gensim.models.word2vec.Word2Vec.load(path+file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"take a single phrase as a string, and preprocess, return tokens\"\"\"\n",
    "tokenizer = RegexpTokenizer(r'\\w+') # tokens separated by white spice\n",
    "stops = set(stopwords.words('english')) # list of english stop words\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "def clean(title, rmv_stop_words=False):\n",
    "    tokens = tokenizer.tokenize(title.lower())     # tokenize\n",
    "    if rmv_stop_words:\n",
    "        tokens = [i for i in tokens if not i in stops] # remove stop words\n",
    "    normalized = [lemma.lemmatize(token) for token in tokens] # lemma\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" These generate alternative queries and score them and filter them \"\"\"\n",
    "def generate_alternatives(query, n, model, rmv_stop_words=False):\n",
    "    print('getting similar words')\n",
    "    syns = get_similar(query, n, model, rmv_stop_words) # synonyms\n",
    "    print('making combinations')\n",
    "    combs = get_combinations(syns) # combinations\n",
    "    # generatings probaiblity scores\n",
    "    probs = [model.score([sug])[0] for sug in combs] # probabilities\n",
    "    preds_probs =[(p,q) for p,q in zip(probs,combs)] # combine with queries\n",
    "    q_score = model.score([clean(query)])[0] # score for original query\n",
    "    sd = get_sd(preds_probs)\n",
    "    preds_1sd = [(x,y) for x,y in preds_probs if np.abs(x-q_score)<=sd] # keep just those within 1 sd\n",
    "    preds_1sd.sort(reverse=True)\n",
    "    #print(\"original query: {}\".format(query))\n",
    "    #print(\"score: {}\".format(q_score))\n",
    "    #print(\"sd of all results: {}\".format(sd))\n",
    "    #print(\"number of results within 1 SD of original query score: {}\".format(len(preds_1sd)))\n",
    "    return preds_1sd\n",
    "\n",
    "def get_similar(query, n, model, rmv_stop_words):\n",
    "    q = clean(query, rmv_stop_words=rmv_stop_words)\n",
    "    # turn each word  of query into its own list\n",
    "    d = [[x] for x in q]\n",
    "    for x in d:\n",
    "        # for each word in original query, add topn similar words to list\n",
    "        x.extend([syn for syn,_ in model.most_similar(x[0],topn=n)])\n",
    "    return d\n",
    "\n",
    "def get_combinations(l):\n",
    "    combs = [x for x in product(*l)]\n",
    "    return combs\n",
    "\n",
    "def get_sd(tups):\n",
    "    vals = [x for x,_ in tups]\n",
    "    return np.std(vals)\n",
    "\n",
    "def clean_preds(pred_scores, topn=3):\n",
    "    clean = []\n",
    "    i = 0\n",
    "    for score,query in pred_scores:\n",
    "        i+=1\n",
    "        if i > topn: break\n",
    "        clean.append((score, ' '.join(query)))\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"These query stack overflow and return and parse the serach results for validation\"\"\"\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36',\n",
    "            'Accept': \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "            'Accept_Encoding': 'gzip, deflate, sdch, br', 'Accept_Language':'en-US,en;q=0.8',\n",
    "            'Connection': 'keep-alive'}\n",
    "\n",
    "def get_query_results(query):\n",
    "    url = 'https://stackoverflow.com/search?q='+'+'.join(query)\n",
    "    print(url)\n",
    "    r = requests.get(url)\n",
    "    print(r.status_code)\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "    x = parse_results(soup)\n",
    "    print('found {} results'.format(len(x)))\n",
    "    return x\n",
    "    \n",
    "def parse_results(soup):\n",
    "    l = []\n",
    "    results = soup.find_all(\"div\", class_=\"question-summary search-result\")\n",
    "    i = 0\n",
    "    for result in results:\n",
    "        i += 1\n",
    "        if i > 10:\n",
    "            return l\n",
    "        votes = [v.get_text() for v in result.find_all(\"strong\")]\n",
    "        if len(votes) == 1:\n",
    "            votes.append(1)\n",
    "        link = result.find(\"div\", class_=\"result-link\").find('a')\n",
    "        query = link.attrs['title']\n",
    "        url = link.attrs['href']\n",
    "        votes.extend([query,url])\n",
    "        l.append(tuple(votes))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef make_summaries(key, dic):\\n    d = defaultdict(dict)\\n    votes = 0\\n    answers = 0\\n    for vote,answer,query,_ in dic[list(original)[0]]:\\n        if query in shared:\\n            continue\\n            votes += int(vote)\\n            answers += int(answer)\\n        d[key]['votes'] = votes\\n        d[key]['answers'] = answers\\n        d[key]['unique'] = orig_unique\\n        d[key]['unique_perc'] = len(orig_unique)*1.0/len(orig_items)\\n        \""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" given dictionaries of suggested-queries' results and the original query results,\n",
    "    compares metrics of the returned queries\"\"\"\n",
    "def compare(suggestions, original):\n",
    "    # get result titles from original in a list\n",
    "    orig_items = [title for _,_,title,_ in original[list(original)[0]]]\n",
    "    summaries = defaultdict(dict)\n",
    "    orig_summaries = defaultdict(dict)\n",
    "    for k in suggestions:\n",
    "        # isolate titles for suggested results\n",
    "        sug_items = [title for _,_,title,_ in suggestions[k]]\n",
    "        # identify which results are shared with the original search results\n",
    "        shared = set(orig_items) & set(sug_items)\n",
    "        orig_unique = list(set(orig_items).difference(set(sug_items)))\n",
    "        sug_unique = list(set(sug_items).difference(set(orig_items)))\n",
    "        if len(sug_items) > 0:\n",
    "            concordance = len(shared)*1.0/len(sug_items)\n",
    "        else:\n",
    "            concordance = np.nan\n",
    "        \n",
    "        votes = 0\n",
    "        answers = 0\n",
    "        for vote,answer,query,_ in original[list(original)[0]]:\n",
    "            if query in shared:\n",
    "                continue\n",
    "            votes += int(vote)\n",
    "            answers += int(answer)\n",
    "        orig_summaries[k]['unique'] = len(orig_unique)\n",
    "        try: \n",
    "            orig_summaries[k]['avg_unique_votes'] = votes*1.0/orig_summaries[k]['unique']\n",
    "            orig_summaries[k]['avg_unique_answers'] = answers*1.0/orig_summaries[k]['unique']\n",
    "        except ZeroDivisionError:\n",
    "            orig_summaries[k]['avg_unique_votes'] = 0\n",
    "            orig_summaries[k]['avg_unique_answers'] = 0\n",
    "        orig_summaries[k]['titles'] = orig_unique\n",
    "        orig_summaries[k]['concordance'] = concordance\n",
    "        \n",
    "        # calculate sum of votes and answers for all unique search results in suggestion\n",
    "        votes = 0\n",
    "        answers = 0\n",
    "        #distances = []\n",
    "        for vote,answer,query,url in suggestions[k]:\n",
    "            if query in shared:\n",
    "                continue\n",
    "            votes += int(vote)\n",
    "            answers += int(answer)\n",
    "            #distances.append ()# cosine distance fucntion here)\n",
    "            # concordance\n",
    "        summaries[k]['unique'] = len(sug_unique)\n",
    "        summaries[k]['titles'] = sug_unique\n",
    "        summaries[k]['concordance'] = concordance\n",
    "        try: \n",
    "            summaries[k]['avg_unique_votes'] = votes*1.0/summaries[k]['unique']\n",
    "            summaries[k]['avg_unique_answers'] = answers*1.0/summaries[k]['unique']\n",
    "        except ZeroDivisionError:\n",
    "            summaries[k]['avg_unique_votes'] = 0\n",
    "            summaries[k]['avg_unique_answers'] = 0\n",
    "    return summaries, orig_summaries\n",
    "\n",
    "\"\"\"\n",
    "def make_summaries(key, dic):\n",
    "    d = defaultdict(dict)\n",
    "    votes = 0\n",
    "    answers = 0\n",
    "    for vote,answer,query,_ in dic[list(original)[0]]:\n",
    "        if query in shared:\n",
    "            continue\n",
    "            votes += int(vote)\n",
    "            answers += int(answer)\n",
    "        d[key]['votes'] = votes\n",
    "        d[key]['answers'] = answers\n",
    "        d[key]['unique'] = orig_unique\n",
    "        d[key]['unique_perc'] = len(orig_unique)*1.0/len(orig_items)\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(queries, n_syns, topn, model, dic):\n",
    "    #results_dict = defaultdict(dict)\n",
    "    i = 0\n",
    "    for q in queries:\n",
    "        i+=1\n",
    "        print('starting query {}'.format(i))\n",
    "        dic[q] = evaluate_query(q, n_syns, topn, model)\n",
    "        if dic[q] == None:\n",
    "            print('query {} failed'.format(i))\n",
    "            continue\n",
    "        print('query {} completed'.format(i))\n",
    "    return dic\n",
    "        #results_dict[q] = evaluate_query(q, n_syns, topn, model)\n",
    "    #return results_dict\n",
    "\n",
    "def evaluate_query(orig_query, n_syns, topn, model):\n",
    "    # improtant local varaibles\n",
    "    orig_query_vec = clean(orig_query)\n",
    "\n",
    "    # generate, rank, filter suggestions\n",
    "    print('generating predictions')\n",
    "    preds = generate_alternatives(orig_query, n_syns, model)\n",
    "    best_preds = clean_preds(preds, topn)\n",
    "    best_preds2 = [(s,q) for s,q in best_preds if q!=' '.join(orig_query_vec)]\n",
    "    #orig = (model.score([orig_query_vec])[0], ' '.join(orig_query_vec))\n",
    "    \n",
    "    # query each suggestion and scrape relevent metrics\n",
    "    sug_q_results ={}\n",
    "    for _,q in best_preds2:\n",
    "        print('getting search results for \\\"{}\\\"'.format(q))\n",
    "        sug_q_results[q] = get_query_results(clean(q))\n",
    "        print(sug_q_results[q])\n",
    "        #if sug_q_results[q] == []:\n",
    "        #    print('Website returned no results.')\n",
    "        #    return None\n",
    "        time.sleep(2.5)\n",
    "    \n",
    "    # get query results for original query\n",
    "    orig_q_results = {orig_query: get_query_results(orig_query_vec)}\n",
    "    \n",
    "    # get metrics\n",
    "    print('making comparisons')\n",
    "    summaries,orig_summaries = compare(sug_q_results, orig_q_results)\n",
    "    \n",
    "    \n",
    "    # calculate average metrics\n",
    "    avg_answers_dif_score = np.mean([summaries[k]['avg_unique_answers'] - \n",
    "                                  orig_summaries[k]['avg_unique_answers'] for k in summaries])\n",
    "    avg_votes_dif_score = np.mean([summaries[k]['avg_unique_votes'] - \n",
    "                                orig_summaries[k]['avg_unique_votes'] for k in summaries])\n",
    "    avg_unique_items = np.mean([summaries[k]['unique'] for k in summaries])\n",
    "\n",
    "    results = {}\n",
    "    orig_prob = model.score([orig_query_vec])[0]\n",
    "    results['avg_unique_items'] = avg_unique_items\n",
    "    results['avg_answers_dif_score'] = avg_answers_dif_score\n",
    "    results['avg_votes_dif_score'] = avg_votes_dif_score\n",
    "    results['avg_prob_dif_score'] = np.mean([np.exp(prob)-np.exp(orig_prob) for prob,q in best_preds2])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brief test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = ['initializing row pandas dataframe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting query 1\n",
      "generating predictions\n",
      "getting search results for \"initialising column panda dataframe\"\n",
      "https://stackoverflow.com/search?q=initialising+column+panda+dataframe\n",
      "200\n",
      "found 5 results\n",
      "[('3', '1', 'creating subclass form class returning pandas dataFrame', '/questions/14430263/creating-subclass-form-class-returning-pandas-dataframe'), ('2', '1', 'Add pandas Series to a DataFrame, preserving index', '/questions/29805126/add-pandas-series-to-a-dataframe-preserving-index'), ('13', '6', 'Performance issues with pandas and filtering on datetime column', '/questions/38902239/performance-issues-with-pandas-and-filtering-on-datetime-column'), ('0', '2', 'How can I get the <select> tag option chosen by the user using Flask?', '/questions/39741302/how-can-i-get-the-select-tag-option-chosen-by-the-user-using-flask'), ('1', 1, 'Selectively converting float to whole number and decimals in Python pandas', '/questions/45902991/selectively-converting-float-to-whole-number-and-decimals-in-python-pandas/45903037#45903037')]\n",
      "getting search results for \"initialise row panda dataframe\"\n",
      "https://stackoverflow.com/search?q=initialise+row+panda+dataframe\n",
      "200\n",
      "found 1 results\n",
      "[('3', '1', 'Python pandas: banal apply statements incredibly slow', '/questions/31785594/python-pandas-banal-apply-statements-incredibly-slow')]\n",
      "getting search results for \"initialise column panda dataframe\"\n",
      "https://stackoverflow.com/search?q=initialise+column+panda+dataframe\n",
      "200\n",
      "found 5 results\n",
      "[('3', '1', 'creating subclass form class returning pandas dataFrame', '/questions/14430263/creating-subclass-form-class-returning-pandas-dataframe'), ('2', '1', 'Add pandas Series to a DataFrame, preserving index', '/questions/29805126/add-pandas-series-to-a-dataframe-preserving-index'), ('13', '6', 'Performance issues with pandas and filtering on datetime column', '/questions/38902239/performance-issues-with-pandas-and-filtering-on-datetime-column'), ('0', '2', 'How can I get the <select> tag option chosen by the user using Flask?', '/questions/39741302/how-can-i-get-the-select-tag-option-chosen-by-the-user-using-flask'), ('1', 1, 'Selectively converting float to whole number and decimals in Python pandas', '/questions/45902991/selectively-converting-float-to-whole-number-and-decimals-in-python-pandas/45903037#45903037')]\n",
      "getting search results for \"initialise table panda dataframe\"\n",
      "https://stackoverflow.com/search?q=initialise+table+panda+dataframe\n",
      "200\n",
      "found 0 results\n",
      "[]\n",
      "getting search results for \"initialise cell panda dataframe\"\n",
      "https://stackoverflow.com/search?q=initialise+cell+panda+dataframe\n",
      "200\n",
      "found 0 results\n",
      "[]\n",
      "https://stackoverflow.com/search?q=initializing+row+panda+dataframe\n",
      "200\n",
      "found 10 results\n",
      "query 1 completed\n"
     ]
    }
   ],
   "source": [
    "r = defaultdict(dict)\n",
    "results = validate(queries, n_syns=5, topn=5, model=model, dic=r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'initializing row pandas dataframe': {'avg_answers_dif_score': -0.41999999999999993,\n",
       "              'avg_prob_dif_score': 4.7898663e-09,\n",
       "              'avg_unique_items': 2.2000000000000002,\n",
       "              'avg_votes_dif_score': -1.8800000000000001}})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_answers_dif_score</th>\n",
       "      <th>avg_prob_dif_score</th>\n",
       "      <th>avg_unique_items</th>\n",
       "      <th>avg_votes_dif_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>initializing row pandas dataframe</th>\n",
       "      <td>-0.42</td>\n",
       "      <td>4.789866e-09</td>\n",
       "      <td>2.2</td>\n",
       "      <td>-1.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   avg_answers_dif_score  avg_prob_dif_score  \\\n",
       "initializing row pandas dataframe                  -0.42        4.789866e-09   \n",
       "\n",
       "                                   avg_unique_items  avg_votes_dif_score  \n",
       "initializing row pandas dataframe               2.2                -1.88  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting queries for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stackapi import StackAPI\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create connection\n",
    "SITE = StackAPI('stackoverflow')\n",
    "SITE.page_size = 100\n",
    "SITE.max_pages = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attrib(posts, tag):\n",
    "    return [d[tag] for d in posts['items']]\n",
    "\n",
    "def append(filename, dat):    \n",
    "    with open(filename, 'a+') as f:\n",
    "        for item in dat:\n",
    "            f.write(item+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posts(iters, connection, typ, path,fname):\n",
    "    for i in range(iters):\n",
    "        posts = connection.fetch(typ)\n",
    "\n",
    "        # parse and write titles\n",
    "        titles = get_attrib(posts, 'title')\n",
    "        append(path+fname, titles)\n",
    "\n",
    "        print('waiting {} seconds'.format(60+posts['backoff']))\n",
    "        time.sleep(60+posts['backoff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/stevenfelix/Documents/DataScience_local/Insight/'\n",
    "get_posts(1, SITE, 'questions', path, 'recent_titles.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+'recent_titles.txt', 'r') as f:\n",
    "    queries = f.readlines()\n",
    "\n",
    "queries =[html.unescape(q).strip() for q in queries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries\n",
    "## note, lots of special characters will get stripped in my pre-processor, \n",
    "## meaning that the original query will almost always perform better\n",
    "## need to retain proper names and commong things (C++, robots.txt, C#, function())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#queries = ['deep copy pandas dataframe']\n",
    "qs = queries[10:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Building spiral-type function in Python',\n",
       " \"Couldn't register a user on Firebase android\",\n",
       " 'How can I get a unique set of values?']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['get', 'unique', 'set', 'value']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean(qs[2], rmv_stop_words=True)\n",
    "# do remove stop words\n",
    "# don't remove trailing s !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.exp(model.score([clean('function in Haskell')]))\n",
    "b = np.exp(model.score([clean('raise error Python')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.29275721], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b/a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting query 1\n",
      "generating predictions\n",
      "getting search results for \"building quadtree type function with haskell\"\n",
      "https://stackoverflow.com/search?q=building+quadtree+type+function+with+haskell\n",
      "200\n",
      "found 0 results\n",
      "[]\n",
      "getting search results for \"building quadtree type function inside haskell\"\n",
      "https://stackoverflow.com/search?q=building+quadtree+type+function+inside+haskell\n",
      "200\n",
      "found 0 results\n",
      "[]\n",
      "getting search results for \"creating spiral type function in haskell\"\n",
      "https://stackoverflow.com/search?q=creating+spiral+type+function+in+haskell\n",
      "200\n",
      "found 0 results\n",
      "[]\n",
      "getting search results for \"creating quadtree type function in haskell\"\n",
      "https://stackoverflow.com/search?q=creating+quadtree+type+function+in+haskell\n",
      "200\n",
      "found 0 results\n",
      "[]\n",
      "getting search results for \"building quadtree type function within haskell\"\n",
      "https://stackoverflow.com/search?q=building+quadtree+type+function+within+haskell\n",
      "200\n",
      "found 0 results\n",
      "[]\n",
      "https://stackoverflow.com/search?q=building+spiral+type+function+in+python\n",
      "200\n",
      "found 1 results\n",
      "making comparisons\n",
      "query 1 completed\n",
      "starting query 2\n",
      "generating predictions\n",
      "getting search results for \"won t registration a user in stackmob android\"\n",
      "https://stackoverflow.com/search?q=won+t+registration+a+user+in+stackmob+android\n",
      "200\n",
      "found 0 results\n",
      "[]\n",
      "getting search results for \"won t registration a user in firebase android\"\n",
      "https://stackoverflow.com/search?q=won+t+registration+a+user+in+firebase+android\n",
      "200\n",
      "found 0 results\n",
      "[]\n",
      "getting search results for \"won t registration a user on stackmob android\"\n",
      "https://stackoverflow.com/search?q=won+t+registration+a+user+on+stackmob+android\n",
      "200\n",
      "found 0 results\n",
      "[]\n",
      "getting search results for \"don t registration a user in stackmob android\"\n",
      "https://stackoverflow.com/search?q=don+t+registration+a+user+in+stackmob+android\n",
      "200\n",
      "found 0 results\n",
      "[]\n",
      "getting search results for \"don t registration a user in firebase android\"\n",
      "https://stackoverflow.com/search?q=don+t+registration+a+user+in+firebase+android\n",
      "200\n",
      "found 0 results\n",
      "[]\n",
      "https://stackoverflow.com/search?q=couldn+t+register+a+user+on+firebase+android\n",
      "200\n",
      "found 0 results\n",
      "making comparisons\n",
      "query 2 completed\n",
      "starting query 3\n",
      "generating predictions\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-20efeb4137c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_syns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-42-f160497c2da7>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(queries, n_syns, topn, model, dic)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mi\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'starting query {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mdic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_syns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'query {} failed'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-f160497c2da7>\u001b[0m in \u001b[0;36mevaluate_query\u001b[0;34m(orig_query, n_syns, topn, model)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# generate, rank, filter suggestions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'generating predictions'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_alternatives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_syns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mbest_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mbest_preds2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbest_preds\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_query_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-1dde7885cf29>\u001b[0m in \u001b[0;36mgenerate_alternatives\u001b[0;34m(query, n, model, rmv_stop_words)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msyns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmv_stop_words\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# synonyms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcombs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_combinations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msyns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# combinations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msug\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msug\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mpreds_probs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcombs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# combine with queries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mq_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# score for original query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-1dde7885cf29>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msyns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmv_stop_words\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# synonyms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcombs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_combinations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msyns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# combinations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msug\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msug\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mpreds_probs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcombs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# combine with queries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mq_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# score for original query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "r = defaultdict(dict)\n",
    "results = validate(qs, n_syns=3, topn=5, model=model, dic=r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_answers_dif_score</th>\n",
       "      <th>avg_prob_dif_score</th>\n",
       "      <th>avg_unique_items</th>\n",
       "      <th>avg_votes_dif_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>iterating over pandas dataframe</th>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-25.825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 avg_answers_dif_score  avg_prob_dif_score  \\\n",
       "iterating over pandas dataframe                  0.125            0.000004   \n",
       "\n",
       "                                 avg_unique_items  avg_votes_dif_score  \n",
       "iterating over pandas dataframe               8.0              -25.825  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
